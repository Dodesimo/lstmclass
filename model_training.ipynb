{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T22:25:41.753901Z",
     "start_time": "2025-07-25T22:25:41.729406Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:25:45.497834Z",
     "start_time": "2025-07-25T22:25:45.488404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AITextDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ],
   "id": "b5f72a2cdcb36a5f",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:28:13.225170Z",
     "start_time": "2025-07-25T23:28:12.107690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_pickle(\"feature_engineered_embeddings\")\n",
    "shuffled = data.sample(frac = 1)\n",
    "splits = np.array_split(shuffled, 2)"
   ],
   "id": "4521e402a8041a57",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devammondal/PycharmProjects/lstm/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:39:00.624334Z",
     "start_time": "2025-07-25T23:39:00.618478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = splits[0]\n",
    "test = splits[1]"
   ],
   "id": "75cbf92973220d51",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:39:08.795775Z",
     "start_time": "2025-07-25T23:39:00.625152Z"
    }
   },
   "cell_type": "code",
   "source": "print(train)",
   "id": "2bcee3bb681e600a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  generated  \\\n",
      "26673  Everyday, millions of people around the world ...          1   \n",
      "23557  There is no definitive answer to this question...          1   \n",
      "22025  There is no denying that medical care and educ...          1   \n",
      "26917  We all want to make a positive impact on the w...          1   \n",
      "16527  DISTANCE LEARNING\\n\\nI think students can be b...          0   \n",
      "...                                                  ...        ...   \n",
      "18705  \\nFamously competitive rivals, Cristiano Ronal...          1   \n",
      "23126  There is no denying that facts are important. ...          1   \n",
      "19088  \\nCaring for someone with mental health issues...          1   \n",
      "20046  \\nHaving a positive attitude in a difficult si...          1   \n",
      "8272   How to know how a student feels in your class?...          0   \n",
      "\n",
      "                                              embeddings  \n",
      "26673  [[tensor(0.1263), tensor(-0.1514), tensor(-0.3...  \n",
      "23557  [[tensor(0.1713), tensor(-0.3310), tensor(-0.1...  \n",
      "22025  [[tensor(0.0953), tensor(0.1600), tensor(-0.47...  \n",
      "26917  [[tensor(0.3968), tensor(-0.0745), tensor(-0.4...  \n",
      "16527  [[tensor(-0.1801), tensor(-0.4433), tensor(0.0...  \n",
      "...                                                  ...  \n",
      "18705  [[tensor(-0.2106), tensor(-0.3964), tensor(-0....  \n",
      "23126  [[tensor(-0.0128), tensor(-0.0906), tensor(-0....  \n",
      "19088  [[tensor(0.0296), tensor(-0.0291), tensor(-0.4...  \n",
      "20046  [[tensor(0.1332), tensor(-0.6516), tensor(-0.6...  \n",
      "8272   [[tensor(0.0655), tensor(-0.3504), tensor(-0.0...  \n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:39:49.642069Z",
     "start_time": "2025-07-25T23:39:49.637927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = AITextDataset(data=list(train.embeddings), labels=list(train.generated))\n",
    "test_dataset = AITextDataset(data=list(test.embeddings), labels=list(train.generated))"
   ],
   "id": "4cedc28b114601a1",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:21:41.831549Z",
     "start_time": "2025-07-26T00:21:41.828321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, input_length, hidden_length, layers_number, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_length = hidden_length\n",
    "        self.layers_number = layers_number\n",
    "        self.lstm = torch.nn.LSTM(input_length, hidden_length, layers_number, batch_first = True)\n",
    "        self.connected = torch.nn.Linear(hidden_length, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_state = torch.zeros(self.layers_number, x.size(0), self.hidden_length)\n",
    "        memory = torch.zeros(self.layers_number, x.size(0), self.hidden_length)\n",
    "        out, _  = self.lstm(x, (hidden_state, memory))\n",
    "        out = self.connected(out[:, -1, :])\n",
    "        return out"
   ],
   "id": "31696d324f20db2c",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:21:41.837344Z",
     "start_time": "2025-07-26T00:21:41.832252Z"
    }
   },
   "cell_type": "code",
   "source": "model = LSTM(768, 64, 2, 2)",
   "id": "6deea55f7a5327a3",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:04:55.186403Z",
     "start_time": "2025-07-26T00:04:55.182964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters())"
   ],
   "id": "2984ade0692c67d5",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:26:24.743558Z",
     "start_time": "2025-07-26T00:26:24.731791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle = True)"
   ],
   "id": "4936a0fa70d52fdf",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:26:59.305826Z",
     "start_time": "2025-07-26T00:26:57.450880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 1\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        tensor, label = data\n",
    "        prediction = model(tensor)\n",
    "        print(label)\n",
    "        print(prediction)\n",
    "        count = 0 \n",
    "        for j in range(len(prediction)):\n",
    "            classification = 0\n",
    "            if prediction[j][1] > prediction[j][0]:\n",
    "                classification = 1\n",
    "            if label[j] == classification:\n",
    "                count += 1\n",
    "        accuracy = count / 50\n",
    "        loss = loss_function(prediction, label)\n",
    "        train_loss.append(loss)\n",
    "        train_acc.append(accuracy)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"epoch {epoch} step {i} loss {loss} accuracy {accuracy}\") \n",
    "    break"
   ],
   "id": "5af12d951142503d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1])\n",
      "tensor([[-0.0668,  0.1146],\n",
      "        [-0.0276,  0.1014],\n",
      "        [-0.0519,  0.0832],\n",
      "        [-0.0335,  0.1057],\n",
      "        [-0.0661,  0.0974],\n",
      "        [ 0.0414,  0.1124],\n",
      "        [-0.0213,  0.1118],\n",
      "        [-0.0706,  0.1017],\n",
      "        [ 0.0438,  0.1020],\n",
      "        [-0.0068,  0.1327],\n",
      "        [-0.0673,  0.0797],\n",
      "        [ 0.0787,  0.1168],\n",
      "        [-0.0151,  0.1075],\n",
      "        [-0.0426,  0.1114],\n",
      "        [-0.0503,  0.1005],\n",
      "        [ 0.0952,  0.1411],\n",
      "        [ 0.0740,  0.1202],\n",
      "        [-0.0578,  0.1047],\n",
      "        [-0.0351,  0.1131],\n",
      "        [-0.0414,  0.1103],\n",
      "        [ 0.0643,  0.1165],\n",
      "        [-0.0311,  0.1031],\n",
      "        [-0.0663,  0.1288],\n",
      "        [-0.0487,  0.0888],\n",
      "        [-0.0736,  0.1313],\n",
      "        [ 0.0232,  0.1055],\n",
      "        [-0.0443,  0.1196],\n",
      "        [-0.0341,  0.0788],\n",
      "        [ 0.0183,  0.1263],\n",
      "        [-0.0736,  0.1027],\n",
      "        [ 0.0181,  0.1023],\n",
      "        [-0.0467,  0.0975],\n",
      "        [-0.0360,  0.1105],\n",
      "        [ 0.0163,  0.1345],\n",
      "        [-0.0381,  0.0923],\n",
      "        [-0.0858,  0.1245],\n",
      "        [-0.0636,  0.1010],\n",
      "        [-0.0826,  0.1159],\n",
      "        [-0.0192,  0.1056],\n",
      "        [ 0.0798,  0.1397],\n",
      "        [-0.0632,  0.0860],\n",
      "        [-0.0691,  0.0988],\n",
      "        [-0.0051,  0.0973],\n",
      "        [-0.0514,  0.1137],\n",
      "        [-0.0013,  0.1318],\n",
      "        [-0.0653,  0.0945],\n",
      "        [-0.0213,  0.1012],\n",
      "        [ 0.0450,  0.1306],\n",
      "        [ 0.0242,  0.1165],\n",
      "        [-0.0247,  0.1099]], grad_fn=<AddmmBackward0>)\n",
      "epoch 0 step 0 loss 0.702700138092041 accuracy 0.42\n",
      "tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1])\n",
      "tensor([[ 0.0499,  0.0995],\n",
      "        [-0.0943,  0.0928],\n",
      "        [-0.0717,  0.0603],\n",
      "        [-0.0258,  0.1390],\n",
      "        [ 0.0242,  0.1070],\n",
      "        [ 0.0674,  0.1451],\n",
      "        [ 0.0131,  0.0896],\n",
      "        [ 0.0315,  0.0868],\n",
      "        [-0.0764,  0.0860],\n",
      "        [-0.0166,  0.0740],\n",
      "        [-0.0428,  0.1389],\n",
      "        [-0.0372,  0.1125],\n",
      "        [-0.0767,  0.0939],\n",
      "        [-0.0176,  0.1310],\n",
      "        [-0.0291,  0.1081],\n",
      "        [-0.0469,  0.1102],\n",
      "        [-0.0311,  0.0908],\n",
      "        [ 0.0190,  0.1139],\n",
      "        [-0.0694,  0.1031],\n",
      "        [ 0.0071,  0.0645],\n",
      "        [-0.0538,  0.1348],\n",
      "        [-0.0312,  0.1063],\n",
      "        [ 0.0659,  0.1493],\n",
      "        [-0.0110,  0.0982],\n",
      "        [-0.0923,  0.0797],\n",
      "        [-0.0666,  0.1145],\n",
      "        [-0.0461,  0.1056],\n",
      "        [-0.0547,  0.1115],\n",
      "        [-0.0445,  0.1023],\n",
      "        [-0.0468,  0.0989],\n",
      "        [-0.1180,  0.1043],\n",
      "        [-0.0453,  0.1374],\n",
      "        [ 0.0353,  0.1717],\n",
      "        [-0.0470,  0.1005],\n",
      "        [-0.0662,  0.0781],\n",
      "        [-0.0336,  0.1116],\n",
      "        [-0.0533,  0.0858],\n",
      "        [-0.0565,  0.1083],\n",
      "        [-0.0830,  0.0862],\n",
      "        [ 0.0264,  0.0859],\n",
      "        [-0.0031,  0.1122],\n",
      "        [ 0.0049,  0.1003],\n",
      "        [-0.0260,  0.1241],\n",
      "        [-0.0578,  0.1269],\n",
      "        [-0.0059,  0.0836],\n",
      "        [-0.0585,  0.1374],\n",
      "        [ 0.0560,  0.1299],\n",
      "        [ 0.0244,  0.1259],\n",
      "        [-0.0601,  0.1011],\n",
      "        [-0.0820,  0.1068]], grad_fn=<AddmmBackward0>)\n",
      "epoch 0 step 1 loss 0.695749044418335 accuracy 0.44\n",
      "tensor([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0])\n",
      "tensor([[ 0.0161,  0.1031],\n",
      "        [ 0.0491,  0.0958],\n",
      "        [ 0.0066,  0.1041],\n",
      "        [-0.0288,  0.1013],\n",
      "        [-0.0341,  0.1175],\n",
      "        [-0.0519,  0.0891],\n",
      "        [-0.0134,  0.0977],\n",
      "        [ 0.0862,  0.1646],\n",
      "        [-0.0410,  0.0817],\n",
      "        [ 0.0400,  0.1225],\n",
      "        [ 0.0304,  0.1112],\n",
      "        [ 0.0090,  0.0902],\n",
      "        [-0.0070,  0.0922],\n",
      "        [-0.0504,  0.1278],\n",
      "        [-0.0516,  0.0941],\n",
      "        [-0.0220,  0.0938],\n",
      "        [ 0.0028,  0.1027],\n",
      "        [ 0.0301,  0.1092],\n",
      "        [ 0.0181,  0.0517],\n",
      "        [ 0.0089,  0.1324],\n",
      "        [-0.0851,  0.0968],\n",
      "        [ 0.0066,  0.1214],\n",
      "        [ 0.0287,  0.1110],\n",
      "        [-0.0135,  0.1477],\n",
      "        [ 0.0968,  0.1392],\n",
      "        [-0.0490,  0.0888],\n",
      "        [ 0.0031,  0.1276],\n",
      "        [ 0.0490,  0.1190],\n",
      "        [-0.0257,  0.0747],\n",
      "        [-0.0229,  0.1069],\n",
      "        [ 0.0284,  0.1270],\n",
      "        [ 0.0283,  0.1162],\n",
      "        [-0.0647,  0.0986],\n",
      "        [-0.0424,  0.0703],\n",
      "        [ 0.0104,  0.1001],\n",
      "        [-0.0599,  0.0919],\n",
      "        [-0.0717,  0.0879],\n",
      "        [-0.0768,  0.1234],\n",
      "        [ 0.0676,  0.1558],\n",
      "        [-0.0558,  0.0802],\n",
      "        [-0.0296,  0.0903],\n",
      "        [-0.0284,  0.1578],\n",
      "        [ 0.0228,  0.1376],\n",
      "        [-0.0734,  0.1215],\n",
      "        [-0.0387,  0.1097],\n",
      "        [-0.0886,  0.1595],\n",
      "        [ 0.0498,  0.1116],\n",
      "        [-0.0101,  0.1148],\n",
      "        [-0.0160,  0.1150],\n",
      "        [-0.0035,  0.1188]], grad_fn=<AddmmBackward0>)\n",
      "epoch 0 step 2 loss 0.7097722887992859 accuracy 0.32\n",
      "tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1])\n",
      "tensor([[-0.0446,  0.1078],\n",
      "        [ 0.0130,  0.1282],\n",
      "        [-0.0143,  0.0962],\n",
      "        [-0.0220,  0.0659],\n",
      "        [-0.0360,  0.1196],\n",
      "        [-0.1023,  0.0797],\n",
      "        [-0.0572,  0.1007],\n",
      "        [-0.0409,  0.0908],\n",
      "        [-0.0471,  0.0820],\n",
      "        [ 0.0013,  0.0898],\n",
      "        [-0.0528,  0.0981],\n",
      "        [ 0.0719,  0.1784],\n",
      "        [ 0.0443,  0.1191],\n",
      "        [ 0.0549,  0.1185],\n",
      "        [ 0.0400,  0.1690],\n",
      "        [ 0.0831,  0.1223],\n",
      "        [-0.0439,  0.1014],\n",
      "        [-0.0791,  0.1075],\n",
      "        [ 0.0349,  0.0971],\n",
      "        [-0.0215,  0.0971],\n",
      "        [-0.0643,  0.0820],\n",
      "        [ 0.0451,  0.1011],\n",
      "        [-0.0442,  0.1087],\n",
      "        [-0.0640,  0.0793],\n",
      "        [ 0.0814,  0.1214],\n",
      "        [-0.0240,  0.0794],\n",
      "        [-0.0865,  0.0760],\n",
      "        [ 0.0215,  0.1220],\n",
      "        [ 0.0762,  0.1446],\n",
      "        [-0.0434,  0.1145],\n",
      "        [-0.0213,  0.1236],\n",
      "        [ 0.0688,  0.1323],\n",
      "        [-0.0024,  0.1478],\n",
      "        [-0.0372,  0.1317],\n",
      "        [-0.0575,  0.0819],\n",
      "        [-0.0013,  0.0760],\n",
      "        [ 0.0504,  0.1265],\n",
      "        [-0.0268,  0.1295],\n",
      "        [ 0.0404,  0.0891],\n",
      "        [ 0.0258,  0.0973],\n",
      "        [-0.0580,  0.0762],\n",
      "        [-0.0169,  0.0890],\n",
      "        [-0.0259,  0.1181],\n",
      "        [ 0.0550,  0.0844],\n",
      "        [ 0.0152,  0.1237],\n",
      "        [-0.0124,  0.0899],\n",
      "        [ 0.0532,  0.1083],\n",
      "        [-0.0221,  0.1073],\n",
      "        [-0.0410,  0.1035],\n",
      "        [-0.0423,  0.0860]], grad_fn=<AddmmBackward0>)\n",
      "epoch 0 step 3 loss 0.7060301303863525 accuracy 0.38\n",
      "tensor([0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1])\n",
      "tensor([[-0.0420,  0.0974],\n",
      "        [-0.0289,  0.1512],\n",
      "        [-0.0789,  0.0954],\n",
      "        [-0.0584,  0.1045],\n",
      "        [-0.0756,  0.1059],\n",
      "        [-0.0716,  0.0980],\n",
      "        [-0.0499,  0.0891],\n",
      "        [-0.0224,  0.1558],\n",
      "        [-0.0322,  0.0955],\n",
      "        [-0.0751,  0.1551],\n",
      "        [-0.0620,  0.1074],\n",
      "        [-0.0656,  0.1162],\n",
      "        [-0.0620,  0.1592],\n",
      "        [-0.0697,  0.1203],\n",
      "        [ 0.0102,  0.0921],\n",
      "        [-0.0546,  0.0928],\n",
      "        [-0.0507,  0.0831],\n",
      "        [ 0.0394,  0.1542],\n",
      "        [ 0.0256,  0.1154],\n",
      "        [-0.0724,  0.1158],\n",
      "        [ 0.0063,  0.1105],\n",
      "        [-0.0379,  0.1378],\n",
      "        [-0.0764,  0.1011],\n",
      "        [ 0.0687,  0.0964],\n",
      "        [-0.0556,  0.1206],\n",
      "        [-0.0248,  0.1295],\n",
      "        [ 0.0145,  0.1130],\n",
      "        [ 0.0179,  0.1344],\n",
      "        [-0.0656,  0.1219],\n",
      "        [ 0.0458,  0.1168],\n",
      "        [-0.0523,  0.1302],\n",
      "        [-0.0524,  0.1158],\n",
      "        [-0.0389,  0.0964],\n",
      "        [-0.0429,  0.0569],\n",
      "        [-0.0232,  0.0972],\n",
      "        [ 0.0051,  0.1617],\n",
      "        [ 0.0402,  0.1414],\n",
      "        [-0.0428,  0.1061],\n",
      "        [-0.0494,  0.0925],\n",
      "        [-0.0577,  0.0846],\n",
      "        [-0.0508,  0.1057],\n",
      "        [ 0.0316,  0.1175],\n",
      "        [-0.0231,  0.1431],\n",
      "        [-0.0246,  0.1430],\n",
      "        [ 0.0892,  0.1814],\n",
      "        [-0.0612,  0.0996],\n",
      "        [ 0.0373,  0.1465],\n",
      "        [-0.0375,  0.1079],\n",
      "        [-0.0896,  0.1108],\n",
      "        [-0.0341,  0.1069]], grad_fn=<AddmmBackward0>)\n",
      "epoch 0 step 4 loss 0.6954923868179321 accuracy 0.48\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ae3f4c81b2b25e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
