{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T22:25:41.753901Z",
     "start_time": "2025-07-25T22:25:41.729406Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:25:45.497834Z",
     "start_time": "2025-07-25T22:25:45.488404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AITextDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ],
   "id": "b5f72a2cdcb36a5f",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:54:40.419997Z",
     "start_time": "2025-07-25T22:54:40.358544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"feature_engineered_embeddings\")\n",
    "shuffled = data.sample(frac = 1)\n",
    "splits = np.array_split(shuffled, 2)"
   ],
   "id": "4521e402a8041a57",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devammondal/PycharmProjects/lstm/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:55:23.611637Z",
     "start_time": "2025-07-25T22:55:23.513691Z"
    }
   },
   "cell_type": "code",
   "source": "print(torch.tensor(float(data['embeddings'][0])))",
   "id": "64ab69fa4617c034",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[[-0.0809724  -0.08486272 -0.6065865  ... -0.4288915   0.49864244\\n   0.21013789]\\n [ 0.16275167  0.19716358 -0.63289344 ...  0.6522909   1.16892\\n   0.40316024]\\n [ 0.0872129   0.29124722  0.32916912 ...  0.7439031   1.0377266\\n   0.703288  ]\\n ...\\n [ 0.20495985  0.5605411   0.2448235  ... -0.22918493 -0.01759733\\n  -0.2825431 ]\\n [ 0.08957516 -0.01565889  0.3656449  ... -0.08716358 -0.15552682\\n  -0.48998094]\\n [ 0.17319556  0.28364557  0.566096   ... -0.13319233 -0.12998258\\n  -0.47630036]]'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[52]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28mprint\u001B[39m(torch.tensor(\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43membeddings\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m))\n",
      "\u001B[31mValueError\u001B[39m: could not convert string to float: '[[-0.0809724  -0.08486272 -0.6065865  ... -0.4288915   0.49864244\\n   0.21013789]\\n [ 0.16275167  0.19716358 -0.63289344 ...  0.6522909   1.16892\\n   0.40316024]\\n [ 0.0872129   0.29124722  0.32916912 ...  0.7439031   1.0377266\\n   0.703288  ]\\n ...\\n [ 0.20495985  0.5605411   0.2448235  ... -0.22918493 -0.01759733\\n  -0.2825431 ]\\n [ 0.08957516 -0.01565889  0.3656449  ... -0.08716358 -0.15552682\\n  -0.48998094]\\n [ 0.17319556  0.28364557  0.566096   ... -0.13319233 -0.12998258\\n  -0.47630036]]'"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:15:46.005829Z",
     "start_time": "2025-07-25T22:15:45.996863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = splits[0]\n",
    "test = splits[1]"
   ],
   "id": "75cbf92973220d51",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:15:46.797678Z",
     "start_time": "2025-07-25T22:15:46.790442Z"
    }
   },
   "cell_type": "code",
   "source": "print(train)",
   "id": "2bcee3bb681e600a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  generated  \\\n",
      "383  There are many advantages to limiting car usag...          0   \n",
      "291  The Electoral College is a process that the fo...          0   \n",
      "198  I think asking multiple people for advice is a...          0   \n",
      "275  Do i think the technology is a good value . Ye...          0   \n",
      "136  The use of technology that is able to read the...          0   \n",
      "..                                                 ...        ...   \n",
      "464  Sticky situations, we've all been through one ...          0   \n",
      "284  \\nTechnology has profoundly impacted humanity ...          1   \n",
      "415  Phones and Driving\\n\\nAs of 2017, an estimated...          0   \n",
      "97   Space exploration has been a topic of debate s...          1   \n",
      "482  The Face on Mars is a popular pop icon dating ...          0   \n",
      "\n",
      "                                            embeddings  \n",
      "383  tensor([[-0.1165, -0.3161, -0.2490,  ..., -0.1...  \n",
      "291  tensor([[-0.2774, -0.0515,  0.1036,  ..., -0.1...  \n",
      "198  tensor([[ 0.1884, -0.5926, -0.0609,  ..., -0.2...  \n",
      "275  tensor([[-0.0062, -0.0660,  0.1183,  ..., -0.3...  \n",
      "136  tensor([[-0.4558, -0.3758, -0.2771,  ..., -0.4...  \n",
      "..                                                 ...  \n",
      "464  tensor([[-0.0721, -0.1178, -0.2460,  ..., -0.2...  \n",
      "284  tensor([[-0.0861, -0.1620, -0.4311,  ..., -0.1...  \n",
      "415  tensor([[-3.0860e-01, -2.9263e-01, -4.6389e-01...  \n",
      "97   tensor([[-5.7577e-01,  2.3703e-01, -4.2404e-01...  \n",
      "482  tensor([[-7.8254e-01, -1.3424e-01, -3.3697e-02...  \n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:15:48.928156Z",
     "start_time": "2025-07-25T22:15:48.921354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = AITextDataset(data=list(train.embeddings), labels=list(train.generated))\n",
    "test_dataset = AITextDataset(data=list(test.embeddings), labels=list(train.generated))"
   ],
   "id": "4cedc28b114601a1",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:15:49.381739Z",
     "start_time": "2025-07-25T22:15:49.376038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, input, hidden, layers, output):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.layers = layers\n",
    "        self.lstm = torch.nn.LSTM(input, hidden, layers, output, batch_first = True)\n",
    "        self.connected = torch.nn.Linear(hidden, output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_state = torch.zeros(self.layers, x.size(0), self.hidden)\n",
    "        memory = torch.zeros(self.layers, x.size(0), self.hidden)\n",
    "        out, _  = self.lstm(x, (hidden_state, memory))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "id": "31696d324f20db2c",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:15:50.075012Z",
     "start_time": "2025-07-25T22:15:50.065675Z"
    }
   },
   "cell_type": "code",
   "source": "model = LSTM(768, 64, 2, 2)",
   "id": "6deea55f7a5327a3",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:15:50.643268Z",
     "start_time": "2025-07-25T22:15:50.632762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters())"
   ],
   "id": "2984ade0692c67d5",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:15:51.217376Z",
     "start_time": "2025-07-25T22:15:51.212214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle = True)"
   ],
   "id": "4936a0fa70d52fdf",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:15:52.016552Z",
     "start_time": "2025-07-25T22:15:51.836416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 100\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        tensor, label = data\n",
    "        tensor = torch.tensor(tensor[0])\n",
    "        \n",
    "        prediction = model(tensor[0])\n",
    "        \n",
    "        loss = loss_function(prediction, label)\n",
    "        accuracy = (prediction.round() == label).float().mean()\n",
    "        \n",
    "        train_loss.append(loss)\n",
    "        train_acc.append(accuracy)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"epoch {epoch} step {i} loss {loss} accuracy {accuracy}\")"
   ],
   "id": "5af12d951142503d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[32m      8\u001B[39m     tensor, label = data\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m     tensor = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m     prediction = model(tensor[\u001B[32m0\u001B[39m])\n\u001B[32m     13\u001B[39m     loss = loss_function(prediction, label)\n",
      "\u001B[31mTypeError\u001B[39m: new(): invalid data type 'str'"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ae3f4c81b2b25e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
