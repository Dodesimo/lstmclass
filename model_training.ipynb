{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T22:25:41.753901Z",
     "start_time": "2025-07-25T22:25:41.729406Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:25:45.497834Z",
     "start_time": "2025-07-25T22:25:45.488404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AITextDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ],
   "id": "b5f72a2cdcb36a5f",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:28:13.225170Z",
     "start_time": "2025-07-25T23:28:12.107690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_pickle(\"feature_engineered_embeddings\")\n",
    "shuffled = data.sample(frac = 1)\n",
    "splits = np.array_split(shuffled, 2)"
   ],
   "id": "4521e402a8041a57",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devammondal/PycharmProjects/lstm/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:39:00.624334Z",
     "start_time": "2025-07-25T23:39:00.618478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = splits[0]\n",
    "test = splits[1]"
   ],
   "id": "75cbf92973220d51",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:39:08.795775Z",
     "start_time": "2025-07-25T23:39:00.625152Z"
    }
   },
   "cell_type": "code",
   "source": "print(train)",
   "id": "2bcee3bb681e600a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  generated  \\\n",
      "26673  Everyday, millions of people around the world ...          1   \n",
      "23557  There is no definitive answer to this question...          1   \n",
      "22025  There is no denying that medical care and educ...          1   \n",
      "26917  We all want to make a positive impact on the w...          1   \n",
      "16527  DISTANCE LEARNING\\n\\nI think students can be b...          0   \n",
      "...                                                  ...        ...   \n",
      "18705  \\nFamously competitive rivals, Cristiano Ronal...          1   \n",
      "23126  There is no denying that facts are important. ...          1   \n",
      "19088  \\nCaring for someone with mental health issues...          1   \n",
      "20046  \\nHaving a positive attitude in a difficult si...          1   \n",
      "8272   How to know how a student feels in your class?...          0   \n",
      "\n",
      "                                              embeddings  \n",
      "26673  [[tensor(0.1263), tensor(-0.1514), tensor(-0.3...  \n",
      "23557  [[tensor(0.1713), tensor(-0.3310), tensor(-0.1...  \n",
      "22025  [[tensor(0.0953), tensor(0.1600), tensor(-0.47...  \n",
      "26917  [[tensor(0.3968), tensor(-0.0745), tensor(-0.4...  \n",
      "16527  [[tensor(-0.1801), tensor(-0.4433), tensor(0.0...  \n",
      "...                                                  ...  \n",
      "18705  [[tensor(-0.2106), tensor(-0.3964), tensor(-0....  \n",
      "23126  [[tensor(-0.0128), tensor(-0.0906), tensor(-0....  \n",
      "19088  [[tensor(0.0296), tensor(-0.0291), tensor(-0.4...  \n",
      "20046  [[tensor(0.1332), tensor(-0.6516), tensor(-0.6...  \n",
      "8272   [[tensor(0.0655), tensor(-0.3504), tensor(-0.0...  \n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:39:49.642069Z",
     "start_time": "2025-07-25T23:39:49.637927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = AITextDataset(data=list(train.embeddings), labels=list(train.generated))\n",
    "test_dataset = AITextDataset(data=list(test.embeddings), labels=list(train.generated))"
   ],
   "id": "4cedc28b114601a1",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:40:34.047574Z",
     "start_time": "2025-07-25T23:40:34.039557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, input, hidden, layers, output):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.layers = layers\n",
    "        self.lstm = torch.nn.LSTM(input, hidden, layers, output, batch_first = True)\n",
    "        self.connected = torch.nn.Linear(hidden, output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_state = torch.zeros(self.layers, x.size(0), self.hidden)\n",
    "        memory = torch.zeros(self.layers, x.size(0), self.hidden)\n",
    "        out, _  = self.lstm(x, (hidden_state, memory))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "id": "31696d324f20db2c",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:40:34.055739Z",
     "start_time": "2025-07-25T23:40:34.048699Z"
    }
   },
   "cell_type": "code",
   "source": "model = LSTM(768, 64, 2, 2)",
   "id": "6deea55f7a5327a3",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:42:28.466887Z",
     "start_time": "2025-07-25T23:42:28.458464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters())"
   ],
   "id": "2984ade0692c67d5",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:43:11.846583Z",
     "start_time": "2025-07-25T23:43:11.841557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle = True)"
   ],
   "id": "4936a0fa70d52fdf",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:45:43.684923Z",
     "start_time": "2025-07-25T23:45:43.543874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 100\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        tensor, label = data\n",
    "        \n",
    "        prediction = model(tensor)\n",
    "        loss = loss_function(prediction, label)\n",
    "        accuracy = (prediction.round() == label).float().mean()\n",
    "        \n",
    "        train_loss.append(loss)\n",
    "        train_acc.append(accuracy)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"epoch {epoch} step {i} loss {loss} accuracy {accuracy}\")"
   ],
   "id": "5af12d951142503d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "lstm() received an invalid combination of arguments - got (Tensor, tuple, list, int, int, float, bool, bool, bool), but expected one of:\n * (Tensor data, Tensor batch_sizes, tuple of Tensors hx, tuple of Tensors params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional)\n      didn't match because some of the arguments have invalid types: (Tensor, !tuple of (Tensor, Tensor)!, !list of [Parameter, Parameter, Parameter, Parameter, Parameter, Parameter, Parameter, Parameter]!, !int!, !int!, !float!, !bool!, bool, bool)\n * (Tensor input, tuple of Tensors hx, tuple of Tensors params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional, bool batch_first)\n      didn't match because some of the arguments have invalid types: (Tensor, !tuple of (Tensor, Tensor)!, !list of [Parameter, Parameter, Parameter, Parameter, Parameter, Parameter, Parameter, Parameter]!, !int!, int, float, bool, bool, bool)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[76]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[32m      8\u001B[39m     tensor, label = data\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     prediction = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m     loss = loss_function(prediction, label)\n\u001B[32m     12\u001B[39m     accuracy = (prediction.round() == label).float().mean()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/lstm/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/lstm/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[70]\u001B[39m\u001B[32m, line 12\u001B[39m, in \u001B[36mLSTM.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     10\u001B[39m hidden_state = torch.zeros(\u001B[38;5;28mself\u001B[39m.layers, x.size(\u001B[32m0\u001B[39m), \u001B[38;5;28mself\u001B[39m.hidden)\n\u001B[32m     11\u001B[39m memory = torch.zeros(\u001B[38;5;28mself\u001B[39m.layers, x.size(\u001B[32m0\u001B[39m), \u001B[38;5;28mself\u001B[39m.hidden)\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m out, _  = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     13\u001B[39m out = \u001B[38;5;28mself\u001B[39m.fc(out[:, -\u001B[32m1\u001B[39m, :])\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/lstm/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/lstm/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/lstm/venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1124\u001B[39m, in \u001B[36mLSTM.forward\u001B[39m\u001B[34m(self, input, hx)\u001B[39m\n\u001B[32m   1121\u001B[39m         hx = \u001B[38;5;28mself\u001B[39m.permute_hidden(hx, sorted_indices)\n\u001B[32m   1123\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1124\u001B[39m     result = \u001B[43m_VF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1125\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1126\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1127\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m   1128\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1129\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1130\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1131\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1132\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1133\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbatch_first\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1134\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1135\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1136\u001B[39m     result = _VF.lstm(\n\u001B[32m   1137\u001B[39m         \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   1138\u001B[39m         batch_sizes,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1145\u001B[39m         \u001B[38;5;28mself\u001B[39m.bidirectional,\n\u001B[32m   1146\u001B[39m     )\n",
      "\u001B[31mTypeError\u001B[39m: lstm() received an invalid combination of arguments - got (Tensor, tuple, list, int, int, float, bool, bool, bool), but expected one of:\n * (Tensor data, Tensor batch_sizes, tuple of Tensors hx, tuple of Tensors params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional)\n      didn't match because some of the arguments have invalid types: (Tensor, !tuple of (Tensor, Tensor)!, !list of [Parameter, Parameter, Parameter, Parameter, Parameter, Parameter, Parameter, Parameter]!, !int!, !int!, !float!, !bool!, bool, bool)\n * (Tensor input, tuple of Tensors hx, tuple of Tensors params, bool has_biases, int num_layers, float dropout, bool train, bool bidirectional, bool batch_first)\n      didn't match because some of the arguments have invalid types: (Tensor, !tuple of (Tensor, Tensor)!, !list of [Parameter, Parameter, Parameter, Parameter, Parameter, Parameter, Parameter, Parameter]!, !int!, int, float, bool, bool, bool)\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ae3f4c81b2b25e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
