{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T22:25:41.753901Z",
     "start_time": "2025-07-25T22:25:41.729406Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T22:25:45.497834Z",
     "start_time": "2025-07-25T22:25:45.488404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AITextDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label"
   ],
   "id": "b5f72a2cdcb36a5f",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:28:13.225170Z",
     "start_time": "2025-07-25T23:28:12.107690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_pickle(\"feature_engineered_embeddings\")\n",
    "shuffled = data.sample(frac = 1)\n",
    "splits = np.array_split(shuffled, 2)"
   ],
   "id": "4521e402a8041a57",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devammondal/PycharmProjects/lstm/venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:39:00.624334Z",
     "start_time": "2025-07-25T23:39:00.618478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = splits[0]\n",
    "test = splits[1]"
   ],
   "id": "75cbf92973220d51",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:39:08.795775Z",
     "start_time": "2025-07-25T23:39:00.625152Z"
    }
   },
   "cell_type": "code",
   "source": "print(train)",
   "id": "2bcee3bb681e600a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  generated  \\\n",
      "26673  Everyday, millions of people around the world ...          1   \n",
      "23557  There is no definitive answer to this question...          1   \n",
      "22025  There is no denying that medical care and educ...          1   \n",
      "26917  We all want to make a positive impact on the w...          1   \n",
      "16527  DISTANCE LEARNING\\n\\nI think students can be b...          0   \n",
      "...                                                  ...        ...   \n",
      "18705  \\nFamously competitive rivals, Cristiano Ronal...          1   \n",
      "23126  There is no denying that facts are important. ...          1   \n",
      "19088  \\nCaring for someone with mental health issues...          1   \n",
      "20046  \\nHaving a positive attitude in a difficult si...          1   \n",
      "8272   How to know how a student feels in your class?...          0   \n",
      "\n",
      "                                              embeddings  \n",
      "26673  [[tensor(0.1263), tensor(-0.1514), tensor(-0.3...  \n",
      "23557  [[tensor(0.1713), tensor(-0.3310), tensor(-0.1...  \n",
      "22025  [[tensor(0.0953), tensor(0.1600), tensor(-0.47...  \n",
      "26917  [[tensor(0.3968), tensor(-0.0745), tensor(-0.4...  \n",
      "16527  [[tensor(-0.1801), tensor(-0.4433), tensor(0.0...  \n",
      "...                                                  ...  \n",
      "18705  [[tensor(-0.2106), tensor(-0.3964), tensor(-0....  \n",
      "23126  [[tensor(-0.0128), tensor(-0.0906), tensor(-0....  \n",
      "19088  [[tensor(0.0296), tensor(-0.0291), tensor(-0.4...  \n",
      "20046  [[tensor(0.1332), tensor(-0.6516), tensor(-0.6...  \n",
      "8272   [[tensor(0.0655), tensor(-0.3504), tensor(-0.0...  \n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T23:39:49.642069Z",
     "start_time": "2025-07-25T23:39:49.637927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = AITextDataset(data=list(train.embeddings), labels=list(train.generated))\n",
    "test_dataset = AITextDataset(data=list(test.embeddings), labels=list(train.generated))"
   ],
   "id": "4cedc28b114601a1",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:04:23.048837Z",
     "start_time": "2025-07-26T00:04:23.045623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "    def __init__(self, input_length, hidden_length, layers_number, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_length = hidden_length\n",
    "        self.layers_number = layers_number\n",
    "        self.lstm = torch.nn.LSTM(input_length, hidden_length, layers_number, batch_first = True)\n",
    "        self.connected = torch.nn.Linear(hidden_length, output_size)\n",
    "        self.softmax = torch.nn.Softmax(dim = -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden_state = torch.zeros(self.layers_number, x.size(0), self.hidden_length)\n",
    "        memory = torch.zeros(self.layers_number, x.size(0), self.hidden_length)\n",
    "        out, _  = self.lstm(x, (hidden_state, memory))\n",
    "        out = self.connected(out[:, -1, :])\n",
    "        result = self.softmax(out)\n",
    "        return result"
   ],
   "id": "31696d324f20db2c",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:04:23.053838Z",
     "start_time": "2025-07-26T00:04:23.049929Z"
    }
   },
   "cell_type": "code",
   "source": "model = LSTM(768, 64, 2, 1)",
   "id": "6deea55f7a5327a3",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:04:55.186403Z",
     "start_time": "2025-07-26T00:04:55.182964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters())"
   ],
   "id": "2984ade0692c67d5",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:05:27.033496Z",
     "start_time": "2025-07-26T00:05:27.030927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=15, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=15, shuffle = True)"
   ],
   "id": "4936a0fa70d52fdf",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T00:09:11.545330Z",
     "start_time": "2025-07-26T00:09:11.301434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 1\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        tensor, label = data\n",
    "        prediction = torch.flatten(model(tensor))\n",
    "        loss = loss_function(prediction, label)\n",
    "        accuracy = (prediction.round() == label).float().mean()\n",
    "        \n",
    "        train_loss.append(loss)\n",
    "        train_acc.append(accuracy)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"epoch {epoch} step {i} loss {loss} accuracy {accuracy}\") \n",
    "    break"
   ],
   "id": "5af12d951142503d",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[104]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m tensor, label = data\n\u001B[32m      9\u001B[39m prediction = torch.flatten(model(tensor))\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m loss = \u001B[43mloss_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m accuracy = (prediction.round() == label).float().mean()\n\u001B[32m     13\u001B[39m train_loss.append(loss)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/lstm/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/lstm/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/lstm/venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:1297\u001B[39m, in \u001B[36mCrossEntropyLoss.forward\u001B[39m\u001B[34m(self, input, target)\u001B[39m\n\u001B[32m   1296\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) -> Tensor:\n\u001B[32m-> \u001B[39m\u001B[32m1297\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1298\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1299\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1300\u001B[39m \u001B[43m        \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1301\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1302\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1303\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1304\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/lstm/venv/lib/python3.12/site-packages/torch/nn/functional.py:3494\u001B[39m, in \u001B[36mcross_entropy\u001B[39m\u001B[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[39m\n\u001B[32m   3492\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   3493\u001B[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001B[32m-> \u001B[39m\u001B[32m3494\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_C\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_nn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3495\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   3496\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3497\u001B[39m \u001B[43m    \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3498\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3499\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3500\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3501\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ae3f4c81b2b25e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
